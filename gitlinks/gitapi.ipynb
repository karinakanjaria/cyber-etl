{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a45890-3704-49c3-8c41-a28da32f2c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import urllib.parse as url\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import jupyter_black  # Amazing python code formatter, this will save you hundreds of hours of work.\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9bc3a0-e2e4-444c-8f10-2cc928067607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274       https://github.com/maxpl0it/CVE-2020-0674-Exploit\n",
       "2100       https://github.com/zephyrproject-rtos/zephyr/p...\n",
       "2102       https://github.com/zephyrproject-rtos/zephyr/p...\n",
       "2105       https://github.com/zephyrproject-rtos/zephyr/p...\n",
       "2110       https://github.com/zephyrproject-rtos/zephyr/p...\n",
       "                                 ...                        \n",
       "1028199        https://github.com/benc-uk/kubeview/issues/95\n",
       "1028202    https://github.com/openedx/xblock-drag-and-dro...\n",
       "1028203    https://github.com/openedx/xblock-drag-and-dro...\n",
       "1028204    https://github.com/openedx/xblock-drag-and-dro...\n",
       "1028205    https://github.com/openedx/xblock-drag-and-dro...\n",
       "Name: url, Length: 34344, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"..\") / \"data\"\n",
    "cve_data = pd.read_feather(data_path / \"all_parsed_cve_references.feather\")\n",
    "github_links = cve_data.loc[\n",
    "    cve_data[\"url\"].str.contains(\"github.com\"), \"url\"\n",
    "].drop_duplicates()\n",
    "github_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1949204a-6a83-4e7e-a519-ca5e08a5b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global used to track when scrip must pause to prevent getting errors\n",
    "# and get as much data as we can as fast as we can.\n",
    "timer = 0\n",
    "\n",
    "\n",
    "def handle_get_requests(api_url, headers=None, data=None, time_to_wait=3):\n",
    "    global timer\n",
    "    \"\"\"\n",
    "    Uses the GitHub API response to wait as appropriate for the specified time after called.\n",
    "    \"\"\"\n",
    "    if timer > 0:\n",
    "        hours = int(timer / 60 / 60)\n",
    "        minutes = int(timer / 60) - (hours * 60)\n",
    "        print(f\"Waiting for {hours}:{minutes} (hh:mm)\", flush=True)\n",
    "        time.sleep(timer)\n",
    "    timer = 0\n",
    "\n",
    "    req_headers = {}\n",
    "    if headers:\n",
    "        req_headers.update(headers)\n",
    "\n",
    "    api_token = get_api_token()\n",
    "    if api_token:\n",
    "        req_headers.update({\"Authorization\": f\"Bearer {api_token}\"})\n",
    "    response = requests.get(api_url, headers=req_headers, data=data)\n",
    "\n",
    "    resp_headers = response.headers\n",
    "    requests_left = int(resp_headers[\"x-ratelimit-remaining\"])\n",
    "    time_left = int(resp_headers[\"x-ratelimit-reset\"]) - datetime.now().timestamp()\n",
    "    if time_left > 0:\n",
    "        time_to_wait = time_left\n",
    "\n",
    "    wait_more = False\n",
    "    if requests_left <= 1:\n",
    "        wait_more = True\n",
    "\n",
    "    if wait_more:\n",
    "        timer = time_to_wait\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_github_repo_paths(raw_urls: pd.Series) -> pd.Series:\n",
    "    # Get each part of the URL and pull out just the repo path\n",
    "    url_parts = raw_urls.str.strip().apply(url.urlsplit)\n",
    "\n",
    "    # Github Repo Links are the first two parts of the \"path\"\n",
    "    repo_paths = (\n",
    "        url_parts.apply(lambda x: x.path)\n",
    "        .str.split(\"/\")\n",
    "        .apply(lambda x: \"/\".join(x[0:3]))\n",
    "    )\n",
    "    # return the final reconstructed URL to each repo\n",
    "    return (\"https://api.github.com/repos\" + repo_paths).drop_duplicates()\n",
    "\n",
    "\n",
    "def get_github_languages(api_url: str, headers=None, data=None) -> Dict[str, Dict]:\n",
    "    languages_url = api_url + \"/languages\"\n",
    "    response = handle_get_requests(languages_url)\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    if response.status_code == 200:\n",
    "        return (api_url, response.json())\n",
    "    else:\n",
    "        return (\"Failed\", str(response.status_code) + \"-\" + response.text)\n",
    "\n",
    "\n",
    "def get_github_contributor_data(\n",
    "    api_url: str, headers=None, data=None\n",
    ") -> List[Dict[str, str]]:\n",
    "    contributor_url = api_url + \"/contributors\"\n",
    "    response = handle_get_requests(contributor_url)\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    if response.status_code == 200:\n",
    "        contib_resp = response.json()\n",
    "        if contib_resp:\n",
    "            return (api_url, contib_resp[0])\n",
    "        else:\n",
    "            return (api_url, None)\n",
    "    else:\n",
    "        return (\"Failed\", str(response.status_code) + \"-\" + response.text)\n",
    "\n",
    "\n",
    "def get_api_token(file_path=Path(\"../api_token.secret\")):\n",
    "    file_path = Path(file_path)\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as secret_path:\n",
    "            return secret_path.readline().strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def make_feather_compatible(df, main_col):\n",
    "    df2 = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            df[main_col].apply(pd.Series),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    df2.drop(columns=main_col, inplace=True)\n",
    "    df2.rename(columns={0: \"url\", 1: main_col}, inplace=True)\n",
    "    df2[\"url\"] = df2[\"url\"].astype(str)\n",
    "    df2[main_col] = df2[main_col].apply(\n",
    "        lambda x: list(x.keys()) if isinstance(x, dict) else [x]\n",
    "    )\n",
    "    return df2[[\"original_index\", \"url\", main_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd824650-b1ca-458f-a9f8-c71f8e21215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 857 URLs since they were already done.\n"
     ]
    }
   ],
   "source": [
    "start = 4000  # Set this to your assigned start values.\n",
    "batch_size = 2450  # Needs to be half the max of 5000, leaving some room for error too.\n",
    "\n",
    "# Put repo paths and netloc together to get repo links.\n",
    "github_repo_urls = get_github_repo_paths(github_links)\n",
    "\n",
    "# Get URLs that have already been queried\n",
    "previous_contrib_data_list = []\n",
    "for contrib_file in data_path.glob(\"contributors*.feather\"):\n",
    "    previous_contrib_data_list.append(pd.read_feather(contrib_file))\n",
    "contrib_github_data = pd.concat(previous_contrib_data_list)\n",
    "previous_urls = contrib_github_data[\"url\"]\n",
    "\n",
    "# Filter out previously queried URLs\n",
    "original_len = len(github_repo_urls)\n",
    "done_filter = github_repo_urls.isin(previous_urls)\n",
    "github_repo_urls = github_repo_urls[~done_filter]\n",
    "new_len = len(github_repo_urls)\n",
    "print(f\"Removed {original_len-new_len} URLs since they were already done.\")\n",
    "\n",
    "# Set up the end point for this batch\n",
    "end = min((start + batch_size), len(github_repo_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebd915-a067-481c-912e-a227d4eaf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query GitHub API for languages\n",
    "language_col = \"languages\"\n",
    "languages = github_repo_urls.iloc[start:end].apply(get_github_languages)\n",
    "languages = languages.reset_index().rename(\n",
    "    columns={\"index\": \"original_index\", \"url\": language_col}\n",
    ")\n",
    "languages2 = make_feather_compatible(languages, language_col)\n",
    "languages2.to_feather(data_path / f\"languages_{start}.feather\")\n",
    "print(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a6d1a-a020-475d-9223-71580f616252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query GitHub API for contributors\n",
    "contrib_col = \"contributors\"\n",
    "contributors = github_repo_urls.iloc[start:end].apply(get_github_contributor_data)\n",
    "contributors = contributors.reset_index().rename(\n",
    "    columns={\"index\": \"original_index\", \"url\": contrib_col}\n",
    ")\n",
    "contributors2 = make_feather_compatible(contributors, contrib_col)\n",
    "contributors2.to_feather(data_path / f\"contributors_{start}.feather\")\n",
    "print(contributors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
